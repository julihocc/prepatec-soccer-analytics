# Optimizaci√≥n de Hiperpar√°metros y Validaci√≥n de Modelos

## Objetivos de Aprendizaje

Al finalizar esta sesi√≥n, los estudiantes podr√°n:
- Comprender la importancia de la optimizaci√≥n de hiperpar√°metros
- Implementar t√©cnicas de b√∫squeda de hiperpar√°metros (Grid Search, Random Search)
- Aplicar validaci√≥n cruzada robusta
- Evaluar y comparar modelos de manera estad√≠sticamente v√°lida
- Interpretar y visualizar resultados de optimizaci√≥n

## 1. Fundamentos de Hiperpar√°metros

### ¬øQu√© son los Hiperpar√°metros?

Los hiperpar√°metros son configuraciones del algoritmo que no se aprenden durante el entrenamiento, sino que deben ser establecidos antes de entrenar el modelo. Controlan el comportamiento del algoritmo de aprendizaje.

#### Diferencia entre Par√°metros e Hiperpar√°metros

**Par√°metros:**
- Se aprenden durante el entrenamiento
- Ejemplos: pesos en redes neuronales, coeficientes en regresi√≥n lineal
- Valores optimizados autom√°ticamente

**Hiperpar√°metros:**
- Se establecen antes del entrenamiento
- Ejemplos: learning rate, n√∫mero de √°rboles, C en SVM
- Requieren optimizaci√≥n manual o autom√°tica

### Importancia de la Optimizaci√≥n

- **Rendimiento:** Hiperpar√°metros √≥ptimos mejoran significativamente el rendimiento
- **Generalizaci√≥n:** Previenen overfitting y underfitting
- **Eficiencia:** Reducen tiempo de entrenamiento y recursos computacionales
- **Robustez:** Hacen el modelo m√°s estable ante variaciones en datos

## 2. Hiperpar√°metros por Algoritmo

### Regresi√≥n Log√≠stica
```python
LogisticRegression(
    C=1.0,                    # Inverso de la regularizaci√≥n
    penalty='l2',             # Tipo de regularizaci√≥n (l1, l2, elasticnet)
    solver='lbfgs',           # Algoritmo de optimizaci√≥n
    max_iter=100,             # N√∫mero m√°ximo de iteraciones
    class_weight=None         # Peso de las clases
)
```

### Random Forest
```python
RandomForestClassifier(
    n_estimators=100,         # N√∫mero de √°rboles
    max_depth=None,           # Profundidad m√°xima de √°rboles
    min_samples_split=2,      # M√≠nimo de muestras para dividir
    min_samples_leaf=1,       # M√≠nimo de muestras en hoja
    max_features='auto',      # N√∫mero de caracter√≠sticas por divisi√≥n
    bootstrap=True,           # Muestreo con reemplazo
    class_weight=None         # Peso de las clases
)
```

### SVM (Support Vector Machine)
```python
SVC(
    C=1.0,                    # Par√°metro de regularizaci√≥n
    kernel='rbf',             # Tipo de kernel (linear, poly, rbf, sigmoid)
    gamma='scale',            # Coeficiente del kernel
    degree=3,                 # Grado del kernel polinomial
    class_weight=None         # Peso de las clases
)
```

### Gradient Boosting
```python
GradientBoostingClassifier(
    n_estimators=100,         # N√∫mero de boosting stages
    learning_rate=0.1,        # Tasa de aprendizaje
    max_depth=3,              # Profundidad m√°xima de √°rboles
    min_samples_split=2,      # M√≠nimo de muestras para dividir
    min_samples_leaf=1,       # M√≠nimo de muestras en hoja
    subsample=1.0,            # Fracci√≥n de muestras por √°rbol
    max_features=None         # N√∫mero de caracter√≠sticas por divisi√≥n
)
```

### Redes Neuronales (MLP)
```python
MLPClassifier(
    hidden_layer_sizes=(100,), # Tama√±o de capas ocultas
    activation='relu',         # Funci√≥n de activaci√≥n
    solver='adam',             # Optimizador
    alpha=0.0001,             # Par√°metro de regularizaci√≥n L2
    learning_rate='constant',  # Estrategia de learning rate
    learning_rate_init=0.001,  # Learning rate inicial
    max_iter=200,             # N√∫mero m√°ximo de iteraciones
    early_stopping=False      # Parada temprana
)
```

## 3. Estrategias de Optimizaci√≥n

### Grid Search (B√∫squeda Exhaustiva)

Grid Search eval√∫a todas las combinaciones posibles de hiperpar√°metros en un grid predefinido.

```python
from sklearn.model_selection import GridSearchCV

# Definir grid de hiperpar√°metros
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Configurar Grid Search
grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    cv=5,                    # Validaci√≥n cruzada de 5 folds
    scoring='accuracy',      # M√©trica de evaluaci√≥n
    n_jobs=-1,              # Usar todos los cores disponibles
    verbose=1               # Mostrar progreso
)

# Ejecutar b√∫squeda
grid_search.fit(X_train, y_train)

# Mejores par√°metros
best_params = grid_search.best_params_
best_score = grid_search.best_score_
```

**Ventajas:**
- Garantiza encontrar el √≥ptimo en el grid
- F√°cil de implementar y entender
- Reproducible

**Desventajas:**
- Computacionalmente costoso
- Crecimiento exponencial con n√∫mero de par√°metros
- Limitado al grid predefinido

### Random Search (B√∫squeda Aleatoria)

Random Search eval√∫a combinaciones aleatorias de hiperpar√°metros.

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# Definir distribuciones de hiperpar√°metros
param_distributions = {
    'n_estimators': randint(50, 200),
    'max_depth': randint(3, 20),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10),
    'max_features': uniform(0.1, 0.9)
}

# Configurar Random Search
random_search = RandomizedSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_distributions=param_distributions,
    n_iter=100,             # N√∫mero de iteraciones
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

# Ejecutar b√∫squeda
random_search.fit(X_train, y_train)
```

**Ventajas:**
- M√°s eficiente que Grid Search
- Puede encontrar mejores soluciones
- Escala mejor con m√°s par√°metros

**Desventajas:**
- No garantiza encontrar el √≥ptimo
- Requiere m√°s configuraci√≥n
- Resultados pueden variar

### Optimizaci√≥n Bayesiana

Usa informaci√≥n de evaluaciones previas para seleccionar pr√≥ximos hiperpar√°metros.

```python
# Usando Optuna (instalaci√≥n: pip install optuna)
import optuna

def objective(trial):
    # Definir hiperpar√°metros a optimizar
    n_estimators = trial.suggest_int('n_estimators', 50, 200)
    max_depth = trial.suggest_int('max_depth', 3, 20)
    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)
    
    # Crear modelo
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        random_state=42
    )
    
    # Evaluaci√≥n con validaci√≥n cruzada
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
    return scores.mean()

# Crear estudio y optimizar
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# Mejores par√°metros
best_params = study.best_params
best_score = study.best_value
```

## 4. Validaci√≥n Cruzada Avanzada

### Validaci√≥n Cruzada Estratificada

Mantiene la proporci√≥n de clases en cada fold.

```python
from sklearn.model_selection import StratifiedKFold

# Configurar validaci√≥n cruzada estratificada
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Evaluar modelo con validaci√≥n cruzada
scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='accuracy')

print(f"Accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")
```

### Validaci√≥n Cruzada Temporal

Para datos con componente temporal.

```python
from sklearn.model_selection import TimeSeriesSplit

# Configurar validaci√≥n temporal
tscv = TimeSeriesSplit(n_splits=5)

# Evaluar modelo preservando orden temporal
scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='accuracy')
```

### Validaci√≥n Cruzada Anidada

Combina selecci√≥n de modelo con evaluaci√≥n de rendimiento.

```python
from sklearn.model_selection import cross_validate

# Validaci√≥n cruzada anidada
def nested_cv(model, param_grid, X, y, cv_outer=5, cv_inner=3):
    outer_scores = []
    
    # Loop externo para evaluaci√≥n
    for train_idx, test_idx in StratifiedKFold(n_splits=cv_outer, shuffle=True, random_state=42).split(X, y):
        X_train_outer, X_test_outer = X[train_idx], X[test_idx]
        y_train_outer, y_test_outer = y[train_idx], y[test_idx]
        
        # Loop interno para selecci√≥n de hiperpar√°metros
        grid_search = GridSearchCV(
            model, param_grid, cv=cv_inner, scoring='accuracy'
        )
        grid_search.fit(X_train_outer, y_train_outer)
        
        # Evaluar en conjunto de prueba externo
        score = grid_search.score(X_test_outer, y_test_outer)
        outer_scores.append(score)
    
    return np.array(outer_scores)

# Ejecutar validaci√≥n cruzada anidada
nested_scores = nested_cv(RandomForestClassifier(random_state=42), param_grid, X_train, y_train)
print(f"Nested CV Score: {nested_scores.mean():.3f} (+/- {nested_scores.std() * 2:.3f})")
```

## 5. M√©tricas de Evaluaci√≥n Avanzadas

### M√©tricas para Clasificaci√≥n Multiclase

```python
from sklearn.metrics import classification_report, confusion_matrix

# Reporte completo de clasificaci√≥n
report = classification_report(y_test, y_pred, target_names=['Home', 'Draw', 'Away'])
print(report)

# Matriz de confusi√≥n
cm = confusion_matrix(y_test, y_pred)
print(cm)
```

### M√©tricas Personalizadas

```python
from sklearn.metrics import make_scorer

def custom_football_score(y_true, y_pred):
    """M√©trica personalizada que penaliza m√°s los errores en partidos importantes"""
    correct = (y_true == y_pred).sum()
    total = len(y_true)
    
    # Penalizar errores en partidos importantes (simplificado)
    penalty = 0
    for i in range(len(y_true)):
        if y_true[i] != y_pred[i]:
            penalty += 1.5  # Penalizaci√≥n por error
    
    return correct / total - penalty / (total * 10)

# Usar m√©trica personalizada
custom_scorer = make_scorer(custom_football_score)
scores = cross_val_score(model, X_train, y_train, cv=5, scoring=custom_scorer)
```

## 6. An√°lisis de Curvas de Aprendizaje

### Curva de Validaci√≥n

Analiza el efecto de un hiperpar√°metro en el rendimiento.

```python
from sklearn.model_selection import validation_curve

# Curva de validaci√≥n para n_estimators
param_range = [10, 50, 100, 200, 500]
train_scores, test_scores = validation_curve(
    RandomForestClassifier(random_state=42),
    X_train, y_train,
    param_name='n_estimators',
    param_range=param_range,
    cv=5,
    scoring='accuracy'
)

# Visualizar curva
plt.figure(figsize=(10, 6))
plt.plot(param_range, train_scores.mean(axis=1), 'o-', label='Training')
plt.plot(param_range, test_scores.mean(axis=1), 'o-', label='Validation')
plt.xlabel('n_estimators')
plt.ylabel('Accuracy')
plt.title('Validation Curve')
plt.legend()
plt.grid(True)
plt.show()
```

### Curva de Aprendizaje

Analiza el efecto del tama√±o del conjunto de entrenamiento.

```python
from sklearn.model_selection import learning_curve

# Curva de aprendizaje
train_sizes, train_scores, test_scores = learning_curve(
    RandomForestClassifier(random_state=42),
    X_train, y_train,
    train_sizes=np.linspace(0.1, 1.0, 10),
    cv=5,
    scoring='accuracy'
)

# Visualizar curva
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores.mean(axis=1), 'o-', label='Training')
plt.plot(train_sizes, test_scores.mean(axis=1), 'o-', label='Validation')
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy')
plt.title('Learning Curve')
plt.legend()
plt.grid(True)
plt.show()
```

## 7. Detecci√≥n de Overfitting y Underfitting

### Indicadores de Overfitting
- Gran diferencia entre accuracy de entrenamiento y validaci√≥n
- Mejora continua en entrenamiento pero estancamiento en validaci√≥n
- Modelo muy complejo para el tama√±o de datos

### Indicadores de Underfitting
- Baja accuracy tanto en entrenamiento como en validaci√≥n
- Modelo demasiado simple para capturar patrones
- Convergencia prematura

### T√©cnicas de Regularizaci√≥n

```python
# Regularizaci√≥n L1 y L2 en Regresi√≥n Log√≠stica
from sklearn.linear_model import LogisticRegression

# L1 (Lasso) - Selecci√≥n autom√°tica de caracter√≠sticas
model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.1)

# L2 (Ridge) - Reducci√≥n de pesos
model_l2 = LogisticRegression(penalty='l2', C=0.1)

# Elastic Net - Combinaci√≥n de L1 y L2
model_elastic = LogisticRegression(penalty='elasticnet', l1_ratio=0.5, solver='saga', C=0.1)
```

## 8. Consideraciones Pr√°cticas

### Tiempo Computacional vs. Rendimiento

```python
import time

# Medir tiempo de optimizaci√≥n
start_time = time.time()
grid_search.fit(X_train, y_train)
optimization_time = time.time() - start_time

print(f"Tiempo de optimizaci√≥n: {optimization_time:.2f} segundos")
print(f"Mejora en accuracy: {grid_search.best_score_ - baseline_score:.3f}")
print(f"Costo por punto de mejora: {optimization_time / (grid_search.best_score_ - baseline_score):.2f} seg/punto")
```

### Estrategias de Optimizaci√≥n Eficiente

1. **B√∫squeda Coarse-to-Fine:**
   - Primero b√∫squeda amplia con pocos valores
   - Luego b√∫squeda fina en regi√≥n prometedora

2. **Paralelizaci√≥n:**
   - Usar `n_jobs=-1` para usar todos los cores
   - Considerar distribuci√≥n en m√∫ltiples m√°quinas

3. **Parada Temprana:**
   - Detener b√∫squeda si no hay mejora significativa
   - Usar validaci√≥n en conjunto holdout

### Reproducibilidad

```python
# Asegurar reproducibilidad
np.random.seed(42)

# Usar random_state en todos los componentes
model = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(model, param_grid, cv=5, random_state=42)
```

## 9. Ejemplo Completo: Optimizaci√≥n para F√∫tbol

```python
# Ejemplo completo de optimizaci√≥n para predicci√≥n de resultados
def optimize_football_model(X_train, y_train, X_test, y_test):
    """Optimizaci√≥n completa para modelo de f√∫tbol"""
    
    # Definir modelos y grids
    models_and_grids = {
        'Random Forest': {
            'model': RandomForestClassifier(random_state=42),
            'params': {
                'n_estimators': [50, 100, 200],
                'max_depth': [5, 10, 15, None],
                'min_samples_split': [2, 5, 10],
                'class_weight': [None, 'balanced']
            }
        },
        'SVM': {
            'model': SVC(random_state=42, probability=True),
            'params': {
                'C': [0.1, 1, 10, 100],
                'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],
                'class_weight': [None, 'balanced']
            }
        },
        'Gradient Boosting': {
            'model': GradientBoostingClassifier(random_state=42),
            'params': {
                'n_estimators': [50, 100, 200],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7],
                'subsample': [0.8, 1.0]
            }
        }
    }
    
    # Optimizar cada modelo
    best_models = {}
    results = {}
    
    for name, config in models_and_grids.items():
        print(f"\nüîÑ Optimizando {name}...")
        
        # Grid search con validaci√≥n cruzada
        grid_search = GridSearchCV(
            config['model'],
            config['params'],
            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
            scoring='accuracy',
            n_jobs=-1,
            verbose=0
        )
        
        # Entrenar
        grid_search.fit(X_train, y_train)
        
        # Evaluar en conjunto de prueba
        test_score = grid_search.score(X_test, y_test)
        
        # Guardar resultados
        best_models[name] = grid_search.best_estimator_
        results[name] = {
            'best_params': grid_search.best_params_,
            'cv_score': grid_search.best_score_,
            'test_score': test_score,
            'model': grid_search.best_estimator_
        }
        
        print(f"‚úÖ {name} - CV: {grid_search.best_score_:.3f}, Test: {test_score:.3f}")
    
    # Seleccionar mejor modelo
    best_model_name = max(results.keys(), key=lambda k: results[k]['test_score'])
    best_model = results[best_model_name]['model']
    
    print(f"\nüèÜ Mejor modelo: {best_model_name}")
    print(f"   Test accuracy: {results[best_model_name]['test_score']:.3f}")
    
    return best_model, results

# Ejecutar optimizaci√≥n
best_model, optimization_results = optimize_football_model(X_train, y_train, X_test, y_test)
```

## 10. Mejores Pr√°cticas

### Do's ‚úÖ
- Usar validaci√≥n cruzada estratificada
- Separar datos de entrenamiento/validaci√≥n/prueba
- Documentar todos los hiperpar√°metros probados
- Considerar tiempo computacional vs. mejora
- Validar estabilidad de resultados

### Don'ts ‚ùå
- No usar datos de prueba para optimizaci√≥n
- No ignorar overfitting
- No optimizar solo una m√©trica
- No olvidar reproducibilidad
- No sobre-optimizar en dataset peque√±o

## Pr√≥xima Sesi√≥n

En la siguiente sesi√≥n exploraremos t√©cnicas de interpretabilidad de modelos y an√°lisis de importancia de variables para entender mejor c√≥mo nuestros modelos toman decisiones.

## Recursos Adicionales

- **Documentaci√≥n scikit-learn:** Hyperparameter tuning
- **Paper:** "Random Search for Hyper-Parameter Optimization" (Bergstra & Bengio)
- **Herramienta:** Optuna documentation
- **Tutorial:** "Hyperparameter Tuning with Python" (Towards Data Science)
