{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "082700a8",
   "metadata": {},
   "source": [
    "# **Semana 12: Modelos Avanzados de Clasificaci√≥n**\n",
    "\n",
    "## Ciencia de Datos en el Deporte - An√°lisis Avanzado\n",
    "\n",
    "### üöÄ **Bloque 3: An√°lisis Avanzado y Modelado**\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivos de Aprendizaje:**\n",
    "- ‚úÖ Dominar Random Forest para predicciones deportivas\n",
    "- ‚úÖ Implementar Support Vector Machines (SVM)\n",
    "- ‚úÖ Comparar m√∫ltiples modelos de clasificaci√≥n\n",
    "- ‚úÖ Entender ensemble methods y votaci√≥n\n",
    "- ‚úÖ Seleccionar el mejor modelo para cada situaci√≥n\n",
    "\n",
    "**Herramientas:**\n",
    "- üêç Python\n",
    "- ü§ñ Scikit-learn (Random Forest, SVM, Ensemble)\n",
    "- üìä Pandas (preparaci√≥n de datos)\n",
    "- üìà Matplotlib/Seaborn (comparaci√≥n visual)\n",
    "- üîç Cross-validation (validaci√≥n cruzada)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9fafe",
   "metadata": {},
   "source": [
    "## 1. Repaso: ¬øD√≥nde Quedamos?\n",
    "\n",
    "### 1.1 Lo que Aprendimos en la Semana 11\n",
    "\n",
    "En la semana anterior implementamos nuestro **primer modelo predictivo**:\n",
    "\n",
    "‚úÖ **Regresi√≥n Log√≠stica** para predecir resultados de f√∫tbol  \n",
    "‚úÖ **Preparaci√≥n de datos** con variables relevantes  \n",
    "‚úÖ **Divisi√≥n entrenamiento/prueba** para evaluaci√≥n correcta  \n",
    "‚úÖ **Evaluaci√≥n b√°sica** con matriz de confusi√≥n  \n",
    "\n",
    "### 1.2 ¬øPor qu√© Necesitamos Modelos M√°s Avanzados?\n",
    "\n",
    "La **Regresi√≥n Log√≠stica** es excelente para empezar, pero tiene limitaciones:\n",
    "\n",
    "#### **Limitaciones de Regresi√≥n Log√≠stica:**\n",
    "- ‚ö†Ô∏è **Asume relaciones lineales**: No captura patrones complejos\n",
    "- ‚ö†Ô∏è **Sensible a outliers**: Valores extremos afectan mucho\n",
    "- ‚ö†Ô∏è **Requiere preprocesamiento**: Variables deben estar escaladas\n",
    "\n",
    "#### **Ventajas de Modelos Avanzados:**\n",
    "- ‚úÖ **Capturan patrones complejos**: Relaciones no lineales\n",
    "- ‚úÖ **M√°s robustos**: Manejan mejor datos ruidosos\n",
    "- ‚úÖ **Mayor precisi√≥n**: Especialmente con datasets grandes\n",
    "\n",
    "### 1.3 Modelos que Exploraremos Hoy\n",
    "\n",
    "1. **Random Forest** üå≤: Bosques de √°rboles de decisi√≥n\n",
    "2. **Support Vector Machine (SVM)** ‚ö°: Separaci√≥n √≥ptima de clases\n",
    "3. **Ensemble Voting** üó≥Ô∏è: Combinaci√≥n de m√∫ltiples modelos\n",
    "4. **Comparaci√≥n sistem√°tica** üìä: ¬øCu√°l es mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b0909",
   "metadata": {},
   "source": [
    "## 2. Preparaci√≥n del Entorno\n",
    "\n",
    "### 2.1 Importar Librer√≠as y Cargar Datos\n",
    "\n",
    "Empezaremos cargando las herramientas necesarias y recreando nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e96b6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librer√≠as avanzadas de machine learning cargadas:\n",
      "Random Forest: Bosques de √°rboles de decisi√≥n\n",
      "SVM: Support Vector Machines\n",
      "Ensemble: Combinaci√≥n de modelos\n",
      "Cross-validation: Validaci√≥n cruzada\n",
      "\n",
      "¬°Listos para modelos avanzados!\n"
     ]
    }
   ],
   "source": [
    "# Librer√≠as b√°sicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Librer√≠as de machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuraci√≥n de gr√°ficos\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"Set2\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Librer√≠as avanzadas de machine learning cargadas:\")\n",
    "print(\"Random Forest: Bosques de √°rboles de decisi√≥n\")\n",
    "print(\"SVM: Support Vector Machines\")\n",
    "print(\"Ensemble: Combinaci√≥n de modelos\")\n",
    "print(\"Cross-validation: Validaci√≥n cruzada\")\n",
    "print(\"\\n¬°Listos para modelos avanzados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c534e",
   "metadata": {},
   "source": [
    "### 2.2 Recrear y Expandir el Dataset\n",
    "\n",
    "Vamos a recrear nuestros datos de la semana pasada y a√±adir algunas variables nuevas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821db226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset expandido creado con 926 partidos\n",
      "Variables totales: 16\n",
      "\n",
      "Nuevas variables a√±adidas:\n",
      "- Diferencia en valor de mercado\n",
      "- Jugadores lesionados\n",
      "- D√≠as de descanso\n",
      "- Calidad del equipo\n",
      "\n",
      "Primeros 3 partidos:\n",
      "  equipo_local equipo_visitante  goles_local_ultimos_5  \\\n",
      "0        Betis         Valencia                      1   \n",
      "1     Valencia          Levante                      5   \n",
      "2      Levante         Athletic                      1   \n",
      "\n",
      "   goles_visitante_ultimos_5  victorias_local_ultimos_5  \\\n",
      "0                          6                          3   \n",
      "1                          6                          3   \n",
      "2                         11                          0   \n",
      "\n",
      "   victorias_visitante_ultimos_5  posicion_liga_local  \\\n",
      "0                              0                    9   \n",
      "1                              2                   15   \n",
      "2                              0                   16   \n",
      "\n",
      "   posicion_liga_visitante  es_derbi  diferencia_valor_mercado  \\\n",
      "0                       10         0                  0.175673   \n",
      "1                       10         1                 -4.753666   \n",
      "2                       20         0                  1.532181   \n",
      "\n",
      "   lesionados_local  lesionados_visitante  dias_descanso_local  \\\n",
      "0                 4                     4                    4   \n",
      "1                 3                     3                    7   \n",
      "2                 0                     4                    4   \n",
      "\n",
      "   dias_descanso_visitante  calidad_local  calidad_visitante  \n",
      "0                        7              2                  2  \n",
      "1                        2              2                  1  \n",
      "2                        3              1                  1  \n"
     ]
    }
   ],
   "source": [
    "# Recrear datos de partidos con m√°s variables\n",
    "np.random.seed(42)\n",
    "\n",
    "# Aumentar el dataset para mejor entrenamiento\n",
    "n_partidos = 1000\n",
    "\n",
    "# Equipos con diferentes \"niveles\"\n",
    "equipos_top = ['Real Madrid', 'Barcelona', 'Atletico']\n",
    "equipos_mid = ['Valencia', 'Sevilla', 'Villarreal', 'Betis']\n",
    "equipos_low = ['Athletic', 'Sociedad', 'Getafe', 'Levante', 'Osasuna']\n",
    "todos_equipos = equipos_top + equipos_mid + equipos_low\n",
    "\n",
    "# Funci√≥n para asignar \"calidad\" al equipo\n",
    "def calidad_equipo(equipo):\n",
    "    if equipo in equipos_top:\n",
    "        return 3  # Alta calidad\n",
    "    elif equipo in equipos_mid:\n",
    "        return 2  # Media calidad\n",
    "    else:\n",
    "        return 1  # Baja calidad\n",
    "\n",
    "# Generar datos m√°s realistas\n",
    "datos_partidos = {\n",
    "    'equipo_local': np.random.choice(todos_equipos, n_partidos),\n",
    "    'equipo_visitante': np.random.choice(todos_equipos, n_partidos),\n",
    "    'goles_local_ultimos_5': np.random.randint(0, 15, n_partidos),\n",
    "    'goles_visitante_ultimos_5': np.random.randint(0, 15, n_partidos),\n",
    "    'victorias_local_ultimos_5': np.random.randint(0, 6, n_partidos),\n",
    "    'victorias_visitante_ultimos_5': np.random.randint(0, 6, n_partidos),\n",
    "    'posicion_liga_local': np.random.randint(1, 21, n_partidos),\n",
    "    'posicion_liga_visitante': np.random.randint(1, 21, n_partidos),\n",
    "    'es_derbi': np.random.choice([0, 1], n_partidos, p=[0.85, 0.15]),\n",
    "    'diferencia_valor_mercado': np.random.normal(0, 20, n_partidos),  # NUEVA: Diferencia en millones ‚Ç¨\n",
    "    'lesionados_local': np.random.randint(0, 5, n_partidos),  # NUEVA: Jugadores lesionados\n",
    "    'lesionados_visitante': np.random.randint(0, 5, n_partidos),\n",
    "    'dias_descanso_local': np.random.randint(2, 8, n_partidos),  # NUEVA: D√≠as de descanso\n",
    "    'dias_descanso_visitante': np.random.randint(2, 8, n_partidos)\n",
    "}\n",
    "\n",
    "# Crear DataFrame\n",
    "df_partidos = pd.DataFrame(datos_partidos)\n",
    "\n",
    "# Eliminar partidos donde un equipo juega contra s√≠ mismo\n",
    "df_partidos = df_partidos[df_partidos['equipo_local'] != df_partidos['equipo_visitante']]\n",
    "\n",
    "# A√±adir calidad de equipos\n",
    "df_partidos['calidad_local'] = df_partidos['equipo_local'].apply(calidad_equipo)\n",
    "df_partidos['calidad_visitante'] = df_partidos['equipo_visitante'].apply(calidad_equipo)\n",
    "\n",
    "print(f\"Dataset expandido creado con {len(df_partidos)} partidos\")\n",
    "print(f\"Variables totales: {len(df_partidos.columns)}\")\n",
    "print(\"\\nNuevas variables a√±adidas:\")\n",
    "print(\"- Diferencia en valor de mercado\")\n",
    "print(\"- Jugadores lesionados\")\n",
    "print(\"- D√≠as de descanso\")\n",
    "print(\"- Calidad del equipo\")\n",
    "\n",
    "print(\"\\nPrimeros 3 partidos:\")\n",
    "print(df_partidos.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e4e05",
   "metadata": {},
   "source": [
    "### 2.3 Crear Variable Objetivo Mejorada\n",
    "\n",
    "Ahora usaremos una l√≥gica m√°s sofisticada que incorpore las nuevas variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59dab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n de resultados (mejorada):\n",
      "resultado\n",
      "Victoria_Local        510\n",
      "Empate                215\n",
      "Victoria_Visitante    201\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Porcentajes:\n",
      "- Victoria_Local: 55.1%\n",
      "- Empate: 23.2%\n",
      "- Victoria_Visitante: 21.7%\n",
      "\n",
      "Dataset final: 926 partidos con distribuci√≥n realista\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n mejorada para simular resultados\n",
    "def simular_resultado_avanzado(row):\n",
    "    \"\"\"\n",
    "    Simula resultado con l√≥gica m√°s realista incluyendo nuevas variables\n",
    "    \"\"\"\n",
    "    # Fortaleza b√°sica (como antes)\n",
    "    fortaleza_local = (\n",
    "        row['goles_local_ultimos_5'] * 0.2 +\n",
    "        row['victorias_local_ultimos_5'] * 0.3 +\n",
    "        (21 - row['posicion_liga_local']) * 0.2 +\n",
    "        row['calidad_local'] * 3 +  # NUEVO: Calidad del equipo\n",
    "        3  # Ventaja de local\n",
    "    )\n",
    "    \n",
    "    fortaleza_visitante = (\n",
    "        row['goles_visitante_ultimos_5'] * 0.2 +\n",
    "        row['victorias_visitante_ultimos_5'] * 0.3 +\n",
    "        (21 - row['posicion_liga_visitante']) * 0.2 +\n",
    "        row['calidad_visitante'] * 3\n",
    "    )\n",
    "    \n",
    "    # Ajustes por nuevas variables\n",
    "    fortaleza_local += row['diferencia_valor_mercado'] * 0.1  # M√°s valor = m√°s fuerte\n",
    "    fortaleza_local -= row['lesionados_local'] * 0.5  # Lesiones debilitan\n",
    "    fortaleza_local += (row['dias_descanso_local'] - 4) * 0.3  # Descanso √≥ptimo = 4 d√≠as\n",
    "    \n",
    "    fortaleza_visitante -= row['diferencia_valor_mercado'] * 0.1\n",
    "    fortaleza_visitante -= row['lesionados_visitante'] * 0.5\n",
    "    fortaleza_visitante += (row['dias_descanso_visitante'] - 4) * 0.3\n",
    "    \n",
    "    # Factor derbi (m√°s impredecible)\n",
    "    if row['es_derbi'] == 1:\n",
    "        factor_aleatorio = np.random.normal(0, 3)  # M√°s variabilidad\n",
    "    else:\n",
    "        factor_aleatorio = np.random.normal(0, 2)\n",
    "    \n",
    "    diferencia = fortaleza_local - fortaleza_visitante + factor_aleatorio\n",
    "    \n",
    "    # Determinar resultado con umbrales ajustados\n",
    "    if diferencia > 2.0:\n",
    "        return 'Victoria_Local'\n",
    "    elif diferencia < -2.0:\n",
    "        return 'Victoria_Visitante'\n",
    "    else:\n",
    "        return 'Empate'\n",
    "\n",
    "# Aplicar la funci√≥n\n",
    "df_partidos['resultado'] = df_partidos.apply(simular_resultado_avanzado, axis=1)\n",
    "\n",
    "# Ver distribuci√≥n\n",
    "print(\"Distribuci√≥n de resultados (mejorada):\")\n",
    "distribucion = df_partidos['resultado'].value_counts()\n",
    "print(distribucion)\n",
    "print(f\"\\nPorcentajes:\")\n",
    "for resultado, cantidad in distribucion.items():\n",
    "    porcentaje = (cantidad / len(df_partidos)) * 100\n",
    "    print(f\"- {resultado}: {porcentaje:.1f}%\")\n",
    "\n",
    "# Verificar que tenemos datos balanceados\n",
    "print(f\"\\nDataset final: {len(df_partidos)} partidos con distribuci√≥n realista\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d2bed",
   "metadata": {},
   "source": [
    "## 3. Random Forest: Bosques de √Årboles de Decisi√≥n\n",
    "\n",
    "### 3.1 ¬øQu√© es Random Forest?\n",
    "\n",
    "**Random Forest** es como tener un **comit√© de expertos** tomando decisiones:\n",
    "\n",
    "#### **Analog√≠a Futbol√≠stica:**\n",
    "Imagina que tienes 100 analistas deportivos, cada uno con una opini√≥n sobre qui√©n ganar√°:\n",
    "- üß† **Cada analista** ve solo parte de la informaci√≥n\n",
    "- üó≥Ô∏è **Todos votan** su predicci√≥n\n",
    "- üèÜ **La mayor√≠a gana** - esa es la predicci√≥n final\n",
    "\n",
    "#### **Ventajas de Random Forest:**\n",
    "- ‚úÖ **Muy preciso**: Combina m√∫ltiples modelos\n",
    "- ‚úÖ **Robusto**: No se \"sobreajusta\" f√°cilmente\n",
    "- ‚úÖ **Maneja datos faltantes**: Autom√°ticamente\n",
    "- ‚úÖ **Indica importancia**: Qu√© variables son m√°s relevantes\n",
    "\n",
    "### 3.2 Implementaci√≥n de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057757af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Random Forest (100 √°rboles)...\n",
      "¬°Random Forest entrenado!\n",
      "\n",
      "Precisi√≥n de Random Forest: 72.58%\n",
      "\n",
      "Importancia de variables en Random Forest:\n",
      "diferencia_valor_mercado: 0.301\n",
      "calidad_visitante: 0.102\n",
      "posicion_liga_visitante: 0.084\n",
      "calidad_local: 0.080\n",
      "posicion_liga_local: 0.075\n"
     ]
    }
   ],
   "source": [
    "# Preparar datos para Random Forest\n",
    "features_rf = [\n",
    "    'goles_local_ultimos_5', 'goles_visitante_ultimos_5',\n",
    "    'victorias_local_ultimos_5', 'victorias_visitante_ultimos_5',\n",
    "    'posicion_liga_local', 'posicion_liga_visitante',\n",
    "    'calidad_local', 'calidad_visitante',\n",
    "    'diferencia_valor_mercado', 'lesionados_local', 'lesionados_visitante',\n",
    "    'dias_descanso_local', 'dias_descanso_visitante', 'es_derbi'\n",
    "]\n",
    "\n",
    "X = df_partidos[features_rf]\n",
    "y = df_partidos['resultado']\n",
    "\n",
    "# Divisi√≥n entrenamiento/prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Crear y entrenar Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,  # 100 √°rboles en el bosque\n",
    "    max_depth=10,      # Profundidad m√°xima de cada √°rbol\n",
    "    random_state=42,\n",
    "    min_samples_split=5,  # M√≠nimo de muestras para dividir\n",
    "    min_samples_leaf=2    # M√≠nimo de muestras en cada hoja\n",
    ")\n",
    "\n",
    "print(\"Entrenando Random Forest (100 √°rboles)...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"¬°Random Forest entrenado!\")\n",
    "\n",
    "# Hacer predicciones\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(f\"\\nPrecisi√≥n de Random Forest: {rf_accuracy:.2%}\")\n",
    "\n",
    "# Mostrar importancia de variables\n",
    "importancias = pd.DataFrame({\n",
    "    'Variable': features_rf,\n",
    "    'Importancia': rf_model.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(\"\\nImportancia de variables en Random Forest:\")\n",
    "for i, row in importancias.head(5).iterrows():\n",
    "    print(f\"{row['Variable']}: {row['Importancia']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362da96",
   "metadata": {},
   "source": [
    "## 4. Support Vector Machine (SVM)\n",
    "\n",
    "### 4.1 ¬øQu√© es SVM?\n",
    "\n",
    "**SVM** busca la **mejor l√≠nea** para separar las clases:\n",
    "\n",
    "#### **Analog√≠a Futbol√≠stica:**\n",
    "Imagina que tienes que **separar equipos** en un campo:\n",
    "- üèüÔ∏è **Campo**: Espacio de caracter√≠sticas (goles, posici√≥n, etc.)\n",
    "- üìè **L√≠nea**: Frontera que separa \"equipos que ganan\" de \"equipos que pierden\"\n",
    "- üéØ **Objetivo**: Encontrar la l√≠nea que mejor separe los grupos\n",
    "\n",
    "#### **Ventajas de SVM:**\n",
    "- ‚úÖ **Muy preciso**: Especialmente con datos complejos\n",
    "- ‚úÖ **Maneja no linealidad**: Con \"kernels\" (trucos matem√°ticos)\n",
    "- ‚úÖ **Robusto con outliers**: No se deja influir por casos extremos\n",
    "\n",
    "#### **Desventajas:**\n",
    "- ‚ö†Ô∏è **Lento con datos grandes**: Puede tardar en entrenar\n",
    "- ‚ö†Ô∏è **Dif√≠cil de interpretar**: \"Caja negra\"\n",
    "\n",
    "### 4.2 Implementaci√≥n de SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59a8d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando SVM (puede tardar un poco)...\n",
      "¬°SVM entrenado!\n",
      "\n",
      "Precisi√≥n de SVM: 80.65%\n",
      "Vectores de soporte utilizados: [172 183 124]\n",
      "Total de vectores de soporte: 479\n"
     ]
    }
   ],
   "source": [
    "# SVM requiere datos escalados (normalizados)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear SVM con kernel RBF (Radial Basis Function)\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',        # Kernel para capturar patrones no lineales\n",
    "    C=1.0,              # Par√°metro de regularizaci√≥n\n",
    "    probability=True,    # Para obtener probabilidades\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando SVM (puede tardar un poco)...\")\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "print(\"¬°SVM entrenado!\")\n",
    "\n",
    "# Hacer predicciones\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "print(f\"\\nPrecisi√≥n de SVM: {svm_accuracy:.2%}\")\n",
    "\n",
    "# Informaci√≥n del modelo\n",
    "print(f\"Vectores de soporte utilizados: {svm_model.n_support_}\")\n",
    "print(f\"Total de vectores de soporte: {sum(svm_model.n_support_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c40f2",
   "metadata": {},
   "source": [
    "## 5. Comparaci√≥n de Modelos\n",
    "\n",
    "### 5.1 Comparar con Regresi√≥n Log√≠stica\n",
    "\n",
    "Vamos a entrenar tambi√©n regresi√≥n log√≠stica para comparar los tres modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Regresi√≥n Log√≠stica para comparaci√≥n\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)  # Usa datos escalados\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "# Crear comparaci√≥n visual\n",
    "modelos = ['Regresi√≥n Log√≠stica', 'Random Forest', 'SVM']\n",
    "precisiones = [lr_accuracy, rf_accuracy, svm_accuracy]\n",
    "\n",
    "# Gr√°fico de comparaci√≥n\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(modelos, precisiones, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "plt.title('Comparaci√≥n de Precisi√≥n entre Modelos', size=16, pad=20)\n",
    "plt.ylabel('Precisi√≥n (%)')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# A√±adir valores encima de las barras\n",
    "for bar, precision in zip(bars, precisiones):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{precision:.2%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumen de resultados\n",
    "print(\"COMPARACI√ìN DE MODELOS:\")\n",
    "print(\"=\" * 40)\n",
    "for modelo, precision in zip(modelos, precisiones):\n",
    "    print(f\"{modelo:20}: {precision:.2%}\")\n",
    "\n",
    "# Encontrar el mejor modelo\n",
    "mejor_idx = np.argmax(precisiones)\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {modelos[mejor_idx]} ({precisiones[mejor_idx]:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc5bb1",
   "metadata": {},
   "source": [
    "### 5.2 An√°lisis Detallado por Modelo\n",
    "\n",
    "Veamos c√≥mo se desempe√±a cada modelo en cada tipo de resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de confusi√≥n para cada modelo\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "modelos_pred = [lr_pred, rf_pred, svm_pred]\n",
    "nombres = ['Regresi√≥n Log√≠stica', 'Random Forest', 'SVM']\n",
    "\n",
    "for i, (pred, nombre) in enumerate(zip(modelos_pred, nombres)):\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Empate', 'Victoria_Local', 'Victoria_Visitante'],\n",
    "                yticklabels=['Empate', 'Victoria_Local', 'Victoria_Visitante'])\n",
    "    axes[i].set_title(f'{nombre}\\nPrecisi√≥n: {precisiones[i]:.2%}')\n",
    "    axes[i].set_ylabel('Realidad' if i == 0 else '')\n",
    "    axes[i].set_xlabel('Predicci√≥n')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reportes detallados\n",
    "print(\"REPORTES DETALLADOS POR CLASE:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for nombre, pred in zip(nombres, modelos_pred):\n",
    "    print(f\"\\n{nombre.upper()}:\")\n",
    "    print(classification_report(y_test, pred, target_names=['Empate', 'Victoria_Local', 'Victoria_Visitante']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139835f",
   "metadata": {},
   "source": [
    "## 6. Ensemble Methods: Combinando Modelos\n",
    "\n",
    "### 6.1 ¬øQu√© son los Ensemble Methods?\n",
    "\n",
    "Los **Ensemble Methods** combinan m√∫ltiples modelos para obtener mejores resultados:\n",
    "\n",
    "#### **Analog√≠a del Comit√© de Expertos:**\n",
    "- üß† **Experto en estad√≠sticas**: Regresi√≥n Log√≠stica\n",
    "- üå≤ **Experto en patrones**: Random Forest  \n",
    "- ‚ö° **Experto en separaci√≥n**: SVM\n",
    "- üó≥Ô∏è **Votaci√≥n final**: Combinan sus opiniones\n",
    "\n",
    "#### **Tipos de Ensemble:**\n",
    "- **Voting (Votaci√≥n)**: Cada modelo vota, gana la mayor√≠a\n",
    "- **Weighted Voting**: Algunos modelos tienen m√°s peso\n",
    "- **Soft Voting**: Usa probabilidades en lugar de votos duros\n",
    "\n",
    "### 6.2 Implementar Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f0928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear ensemble con los tres modelos\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('logistic', lr_model),\n",
    "        ('random_forest', rf_model),\n",
    "        ('svm', svm_model)\n",
    "    ],\n",
    "    voting='soft'  # Usa probabilidades para votaci√≥n m√°s sofisticada\n",
    ")\n",
    "\n",
    "print(\"Entrenando Ensemble Model (combinaci√≥n de los 3 modelos)...\")\n",
    "\n",
    "# Nota: Random Forest usa datos originales, otros usan escalados\n",
    "# Necesitamos entrenar de forma especial\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Crear pipelines para mantener consistencia\n",
    "lr_pipeline = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(random_state=42, max_iter=1000))])\n",
    "svm_pipeline = Pipeline([('scaler', StandardScaler()), ('svm', SVC(kernel='rbf', C=1.0, probability=True, random_state=42))])\n",
    "\n",
    "# Ensemble con pipelines\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr_pipeline', lr_pipeline),\n",
    "        ('rf', rf_model),\n",
    "        ('svm_pipeline', svm_pipeline)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Entrenar ensemble\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "print(\"¬°Ensemble Model entrenado!\")\n",
    "\n",
    "# Hacer predicciones\n",
    "ensemble_pred = ensemble_model.predict(X_test)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_pred)\n",
    "\n",
    "print(f\"\\nPrecisi√≥n del Ensemble: {ensemble_accuracy:.2%}\")\n",
    "\n",
    "# Comparaci√≥n final\n",
    "modelos_final = ['Regresi√≥n Log√≠stica', 'Random Forest', 'SVM', 'Ensemble']\n",
    "precisiones_final = [lr_accuracy, rf_accuracy, svm_accuracy, ensemble_accuracy]\n",
    "\n",
    "print(\"\\nCOMPARACI√ìN FINAL:\")\n",
    "print(\"=\" * 30)\n",
    "for modelo, precision in zip(modelos_final, precisiones_final):\n",
    "    print(f\"{modelo:20}: {precision:.2%}\")\n",
    "\n",
    "mejora = ensemble_accuracy - max(precisiones_final[:-1])\n",
    "print(f\"\\nMejora del Ensemble: +{mejora:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2efdc5f",
   "metadata": {},
   "source": [
    "### 6.3 Visualizaci√≥n Final de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico final comparativo\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Subplot 1: Comparaci√≥n de precisiones\n",
    "plt.subplot(2, 2, 1)\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral', 'gold']\n",
    "bars = plt.bar(modelos_final, precisiones_final, color=colors)\n",
    "plt.title('Comparaci√≥n Final de Modelos')\n",
    "plt.ylabel('Precisi√≥n')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, precision in zip(bars, precisiones_final):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "             f'{precision:.2%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Subplot 2: Matriz de confusi√≥n del mejor modelo\n",
    "plt.subplot(2, 2, 2)\n",
    "mejor_pred = ensemble_pred if ensemble_accuracy == max(precisiones_final) else modelos_pred[np.argmax(precisiones_final[:-1])]\n",
    "cm_mejor = confusion_matrix(y_test, mejor_pred)\n",
    "sns.heatmap(cm_mejor, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Empate', 'Victoria_Local', 'Victoria_Visitante'],\n",
    "            yticklabels=['Empate', 'Victoria_Local', 'Victoria_Visitante'])\n",
    "plt.title('Matriz de Confusi√≥n - Mejor Modelo')\n",
    "plt.ylabel('Realidad')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "\n",
    "# Subplot 3: Importancia de variables (Random Forest)\n",
    "plt.subplot(2, 2, 3)\n",
    "importancias_top = importancias.head(8)\n",
    "plt.barh(importancias_top['Variable'], importancias_top['Importancia'], color='lightblue')\n",
    "plt.title('Variables M√°s Importantes (Random Forest)')\n",
    "plt.xlabel('Importancia')\n",
    "\n",
    "# Subplot 4: Distribuci√≥n de predicciones del ensemble\n",
    "plt.subplot(2, 2, 4)\n",
    "pred_counts = pd.Series(ensemble_pred).value_counts()\n",
    "plt.pie(pred_counts.values, labels=pred_counts.index, autopct='%1.1f%%', colors=['lightcoral', 'lightgreen', 'lightyellow'])\n",
    "plt.title('Distribuci√≥n de Predicciones\\n(Ensemble Model)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumen de insights\n",
    "print(\"INSIGHTS PRINCIPALES:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"1. Mejor modelo individual: {modelos[np.argmax(precisiones)]}\")\n",
    "print(f\"2. Ensemble {'mejora' if ensemble_accuracy > max(precisiones) else 'no mejora'} la precisi√≥n\")\n",
    "print(f\"3. Variables m√°s importantes: {', '.join(importancias.head(3)['Variable'].tolist())}\")\n",
    "print(f\"4. Precisi√≥n promedio de todos los modelos: {np.mean(precisiones_final):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f447a",
   "metadata": {},
   "source": [
    "## 7. Validaci√≥n Cruzada\n",
    "\n",
    "### 7.1 ¬øQu√© es la Validaci√≥n Cruzada?\n",
    "\n",
    "La **validaci√≥n cruzada** es como hacer **m√∫ltiples ex√°menes** para estar seguro del rendimiento:\n",
    "\n",
    "#### **Analog√≠a de Evaluaci√≥n Deportiva:**\n",
    "- üèüÔ∏è **Un partido**: Como usar solo train/test split\n",
    "- üèÜ **Temporada completa**: Como validaci√≥n cruzada\n",
    "- üìä **Promedio de temporada**: Resultado m√°s confiable\n",
    "\n",
    "#### **Proceso:**\n",
    "1. Dividir datos en 5 partes (folds)\n",
    "2. Entrenar con 4 partes, probar con 1\n",
    "3. Repetir 5 veces\n",
    "4. Promediar resultados\n",
    "\n",
    "### 7.2 Implementar Validaci√≥n Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validaci√≥n cruzada para todos los modelos\n",
    "print(\"Realizando validaci√≥n cruzada (5-fold)...\")\n",
    "print(\"Esto puede tardar un momento...\\n\")\n",
    "\n",
    "# Modelos para validar\n",
    "modelos_cv = {\n",
    "    'Logistic Regression': lr_pipeline,\n",
    "    'Random Forest': rf_model,\n",
    "    'SVM': svm_pipeline,\n",
    "    'Ensemble': ensemble_model\n",
    "}\n",
    "\n",
    "resultados_cv = {}\n",
    "\n",
    "for nombre, modelo in modelos_cv.items():\n",
    "    # 5-fold cross validation\n",
    "    scores = cross_val_score(modelo, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    resultados_cv[nombre] = {\n",
    "        'scores': scores,\n",
    "        'mean': scores.mean(),\n",
    "        'std': scores.std()\n",
    "    }\n",
    "    print(f\"{nombre:20}: {scores.mean():.3f} (¬±{scores.std():.3f})\")\n",
    "\n",
    "# Visualizar resultados de validaci√≥n cruzada\n",
    "plt.figure(figsize=(10, 6))\n",
    "nombres_cv = list(resultados_cv.keys())\n",
    "scores_cv = [resultados_cv[nombre]['scores'] for nombre in nombres_cv]\n",
    "\n",
    "# Box plot de los scores\n",
    "bp = plt.boxplot(scores_cv, labels=nombres_cv, patch_artist=True)\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral', 'gold']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.title('Validaci√≥n Cruzada - Distribuci√≥n de Scores')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de estabilidad\n",
    "print(\"\\nAN√ÅLISIS DE ESTABILIDAD:\")\n",
    "print(\"=\" * 30)\n",
    "for nombre, resultado in resultados_cv.items():\n",
    "    estabilidad = \"Alta\" if resultado['std'] < 0.02 else \"Media\" if resultado['std'] < 0.04 else \"Baja\"\n",
    "    print(f\"{nombre:20}: {estabilidad} (std: {resultado['std']:.3f})\")\n",
    "\n",
    "# Mejor modelo seg√∫n validaci√≥n cruzada\n",
    "mejor_cv = max(resultados_cv.items(), key=lambda x: x[1]['mean'])\n",
    "print(f\"\\nüèÜ MEJOR MODELO (CV): {mejor_cv[0]} ({mejor_cv[1]['mean']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bde7bd",
   "metadata": {},
   "source": [
    "## 8. Predicci√≥n Pr√°ctica\n",
    "\n",
    "### 8.1 Usar el Mejor Modelo para Predicciones\n",
    "\n",
    "Ahora usemos nuestro mejor modelo para hacer predicciones realistas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcdac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar el mejor modelo seg√∫n validaci√≥n cruzada\n",
    "mejor_modelo = modelos_cv[mejor_cv[0]]\n",
    "\n",
    "# Crear scenarios de partidos realistas\n",
    "scenarios = [\n",
    "    {\n",
    "        'nombre': 'Cl√°sico: Real Madrid vs Barcelona',\n",
    "        'goles_local_ultimos_5': 13, 'goles_visitante_ultimos_5': 12,\n",
    "        'victorias_local_ultimos_5': 4, 'victorias_visitante_ultimos_5': 4,\n",
    "        'posicion_liga_local': 1, 'posicion_liga_visitante': 2,\n",
    "        'calidad_local': 3, 'calidad_visitante': 3,\n",
    "        'diferencia_valor_mercado': 5, 'lesionados_local': 1, 'lesionados_visitante': 2,\n",
    "        'dias_descanso_local': 4, 'dias_descanso_visitante': 3, 'es_derbi': 1\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'David vs Goliat: Getafe vs Real Madrid',\n",
    "        'goles_local_ultimos_5': 4, 'goles_visitante_ultimos_5': 14,\n",
    "        'victorias_local_ultimos_5': 1, 'victorias_visitante_ultimos_5': 5,\n",
    "        'posicion_liga_local': 15, 'posicion_liga_visitante': 1,\n",
    "        'calidad_local': 1, 'calidad_visitante': 3,\n",
    "        'diferencia_valor_mercado': -50, 'lesionados_local': 3, 'lesionados_visitante': 0,\n",
    "        'dias_descanso_local': 7, 'dias_descanso_visitante': 3, 'es_derbi': 0\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Partido Parejo: Valencia vs Sevilla',\n",
    "        'goles_local_ultimos_5': 8, 'goles_visitante_ultimos_5': 9,\n",
    "        'victorias_local_ultimos_5': 3, 'victorias_visitante_ultimos_5': 3,\n",
    "        'posicion_liga_local': 7, 'posicion_liga_visitante': 6,\n",
    "        'calidad_local': 2, 'calidad_visitante': 2,\n",
    "        'diferencia_valor_mercado': -2, 'lesionados_local': 2, 'lesionados_visitante': 1,\n",
    "        'dias_descanso_local': 4, 'dias_descanso_visitante': 4, 'es_derbi': 0\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"PREDICCIONES CON EL MEJOR MODELO:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    nombre = scenario.pop('nombre')\n",
    "    \n",
    "    # Crear DataFrame para predicci√≥n\n",
    "    partido_df = pd.DataFrame([scenario])\n",
    "    \n",
    "    # Hacer predicci√≥n\n",
    "    prediccion = mejor_modelo.predict(partido_df)[0]\n",
    "    probabilidades = mejor_modelo.predict_proba(partido_df)[0]\n",
    "    \n",
    "    print(f\"\\n{nombre.upper()}:\")\n",
    "    print(f\"Predicci√≥n: {prediccion}\")\n",
    "    \n",
    "    # Mostrar probabilidades\n",
    "    clases = mejor_modelo.classes_ if hasattr(mejor_modelo, 'classes_') else ['Empate', 'Victoria_Local', 'Victoria_Visitante']\n",
    "    print(\"Probabilidades:\")\n",
    "    for clase, prob in zip(clases, probabilidades):\n",
    "        print(f\"  - {clase}: {prob:.1%}\")\n",
    "    \n",
    "    # Nivel de confianza\n",
    "    max_prob = max(probabilidades)\n",
    "    if max_prob > 0.7:\n",
    "        confianza = \"Muy Alta\"\n",
    "    elif max_prob > 0.5:\n",
    "        confianza = \"Alta\"\n",
    "    elif max_prob > 0.4:\n",
    "        confianza = \"Media\"\n",
    "    else:\n",
    "        confianza = \"Baja\"\n",
    "    \n",
    "    print(f\"  Confianza: {confianza} ({max_prob:.1%})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Modelo utilizado: {mejor_cv[0]}\")\n",
    "print(f\"Precisi√≥n en validaci√≥n cruzada: {mejor_cv[1]['mean']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41853ef0",
   "metadata": {},
   "source": [
    "## 9. Resumen y Conclusiones\n",
    "\n",
    "### 9.1 Lo que Aprendimos Hoy\n",
    "\n",
    "‚úÖ **Modelos Avanzados de Clasificaci√≥n**:\n",
    "- **Random Forest**: Bosques de √°rboles para mayor precisi√≥n\n",
    "- **SVM**: Separaci√≥n √≥ptima de clases con kernels\n",
    "- **Ensemble Methods**: Combinaci√≥n de modelos para mejores resultados\n",
    "\n",
    "‚úÖ **T√©cnicas de Evaluaci√≥n**:\n",
    "- **Comparaci√≥n sistem√°tica** de m√∫ltiples modelos\n",
    "- **Validaci√≥n cruzada** para resultados m√°s confiables\n",
    "- **An√°lisis de estabilidad** y robustez\n",
    "\n",
    "‚úÖ **Aplicaci√≥n Pr√°ctica**:\n",
    "- **Predicciones realistas** en scenarios deportivos\n",
    "- **Interpretaci√≥n de probabilidades** y confianza\n",
    "- **Selecci√≥n del mejor modelo** seg√∫n criterios objetivos\n",
    "\n",
    "### 9.2 Conceptos Clave para Recordar\n",
    "\n",
    "üå≤ **Random Forest**: \"Sabidur√≠a de las multitudes\" - muchos √°rboles votan\n",
    "\n",
    "‚ö° **SVM**: Encuentra la mejor frontera para separar clases\n",
    "\n",
    "üó≥Ô∏è **Ensemble**: Combinar expertos para decisiones m√°s acertadas\n",
    "\n",
    "üîÑ **Validaci√≥n Cruzada**: M√∫ltiples evaluaciones para mayor confianza\n",
    "\n",
    "üìä **Feature Importance**: Qu√© variables realmente importan\n",
    "\n",
    "### 9.3 Comparaci√≥n Final de Modelos\n",
    "\n",
    "| Modelo | Ventajas | Desventajas | Cu√°ndo Usar |\n",
    "|--------|----------|-------------|-------------|\n",
    "| **Regresi√≥n Log√≠stica** | Simple, r√°pido, interpretable | Solo relaciones lineales | Baseline, datos peque√±os |\n",
    "| **Random Forest** | Robusto, maneja no linealidad | Menos interpretable | Datos medianos, muchas variables |\n",
    "| **SVM** | Muy preciso, maneja complejidad | Lento, \"caja negra\" | Datos complejos, alta precisi√≥n |\n",
    "| **Ensemble** | Combina fortalezas | M√°s complejo, m√°s lento | M√°xima precisi√≥n posible |\n",
    "\n",
    "### 9.4 Recomendaciones Pr√°cticas\n",
    "\n",
    "#### **Para Proyectos Reales:**\n",
    "1. **Empieza simple**: Regresi√≥n Log√≠stica como baseline\n",
    "2. **Prueba Random Forest**: Buen equilibrio precisi√≥n/interpretabilidad\n",
    "3. **Considera SVM**: Si necesitas m√°xima precisi√≥n\n",
    "4. **Usa Ensemble**: Para competencias o aplicaciones cr√≠ticas\n",
    "\n",
    "#### **Para Optimizar Resultados:**\n",
    "- üîç **Feature Engineering**: Crear variables m√°s informativas\n",
    "- ‚öôÔ∏è **Hyperparameter Tuning**: Ajustar par√°metros de modelos\n",
    "- üìä **M√°s datos**: Siempre ayuda (especialmente para SVM y RF)\n",
    "- üßπ **Limpieza de datos**: Calidad > Cantidad\n",
    "\n",
    "### 9.5 ¬øQu√© Viene Despu√©s?\n",
    "\n",
    "En las siguientes semanas profundizaremos en:\n",
    "- **Semana 13**: M√©tricas avanzadas (ROC-AUC, Precision-Recall)\n",
    "- **Semana 14**: Feature Engineering y optimizaci√≥n de hiperpar√°metros\n",
    "- **Semana 15**: Proyecto final integrador\n",
    "\n",
    "### 9.6 Ejercicio para Practicar\n",
    "\n",
    "**Desaf√≠o**: \n",
    "1. Modifica los scenarios de predicci√≥n y observa c√≥mo cambian los resultados\n",
    "2. ¬øQu√© variables tienen m√°s impacto en las predicciones?\n",
    "3. ¬øEn qu√© scenarios el ensemble funciona mejor que los modelos individuales?\n",
    "\n",
    "¬°Excelente trabajo! Has dominado los modelos avanzados de clasificaci√≥n para an√°lisis deportivo. üèÜ‚öΩü§ñ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
